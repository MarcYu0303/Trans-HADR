## Depth Restoration of Hand-Held Transparent Objects for Human-to-Robot Handover
This is the code implementation of **H**and-**A**ware **D**apth **R**estoration (**HADR**) proposed in ["Depth Restoration of Hand-Held Transparent Objects for Human-to-Robot Handover"](https://marcyu0303.github.io/HADR.github.io/). HADR is a novel method that can restore the depth of hand-held transparent objects by creating an implicit function from the single RGB-D image and introducing hand holding posture as an important guidance. 

![HADR](./images/method.png)

## Citation
If you find this work is useful in your research, please cite:

```latex
@article{yu2024depth,
  title={Depth Restoration of Hand-Held Transparent Objects for Human-to-Robot Handover},
  author={Yu, Ran and Yu, Haixin and Yan, Huang and Song, Ziwu and Li, Shoujie and Ding, Wenbo},
  journal={arXiv preprint arXiv:2408.14997},
  year={2024}
}
```

## Acknowlegement
We sincerely thank the authors of [implicit_depth](https://github.com/NVlabs/implicit_depth) and [SwinDRNet](https://github.com/rnlee1998/SwinDRNet) for open sourcing their methods.